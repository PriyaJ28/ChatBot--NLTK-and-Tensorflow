{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you ask me something about me?</td>\n",
       "      <td>Nah, I'm good.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you ask me anything about myself?</td>\n",
       "      <td>Nah, I'm good.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you ask me anything about me?</td>\n",
       "      <td>Nah, I'm good.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you ask me anything?</td>\n",
       "      <td>Nah, I'm good.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you ask me something?</td>\n",
       "      <td>Nah, I'm good.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Question          Answer  index\n",
       "0     Can you ask me something about me?  Nah, I'm good.    NaN\n",
       "1  Can you ask me anything about myself?  Nah, I'm good.    NaN\n",
       "2      Can you ask me anything about me?  Nah, I'm good.    NaN\n",
       "3               Can you ask me anything?  Nah, I'm good.    NaN\n",
       "4             Can you ask me something?   Nah, I'm good.    NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "df = pd.read_excel('datset.xlsx')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "f = df[\"Answer\"].drop_duplicates()\n",
    "f[\"index1\"] = f.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "intents={}\n",
    "t = []\n",
    "n=f.count()\n",
    "for i in range(n-2):\n",
    "    question = []\n",
    "    response=[]\n",
    "    question.extend((df[\"Question\"][f[\"index1\"][i]:f[\"index1\"][i+1]]))\n",
    "    x = df[\"Answer\"][f[\"index1\"][i]]\n",
    "    response.append((x))\n",
    "    dic = {}\n",
    "    dic[\"questions\"] = question\n",
    "    dic[\"responses\"] = response\n",
    "    dic[\"tag\"] = i\n",
    "    t.append(dic)\n",
    "    intents[\"intents\"] =t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for question in intent['questions']:\n",
    "        #tokenize each word\n",
    "        w = nltk.word_tokenize(str(question))\n",
    "        words.extend(w)\n",
    "        #add documents in the corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9682 documents\n",
      "88 classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "2469 unique lemmatized words [\"'\", \"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", ')', ',', '.', '1', '100', '2', '20', '3', '411', '5', '7', '9', ':', 'a', 'abandoned', 'able', 'abode', 'about', 'abroad', 'absolutely', 'abt', 'accounted', 'accurate', 'acknowledged', 'acquaintance', 'activist', 'activity', 'actor', 'actress', 'actual', 'actually', 'ad', 'address', 'adieu', 'adios', 'adorable', 'adult', 'adventure', 'aesthetically', 'af', 'affection', 'affirmative', 'afraid', 'african', 'after', 'afternoon', 'again', 'against', 'age', 'agender', 'agent', 'agnostic', 'ago', 'agree', 'ah', 'aha', 'ahead', 'ahh', 'ahoy', 'ai', 'air', 'aisle', 'alcohol', 'alexa', 'alien', 'alive', 'all', 'alligator', 'allowed', 'alma', 'aloha', 'alone', 'along', 'already', 'alright', 'altar', 'alternate', 'alternative', 'always', 'am', 'ama', 'amazed', 'amazing', 'america', 'american', 'amigo', 'amuse', 'amused', 'amusement', 'amusing', 'an', 'and', 'android', 'angeles', 'anger', 'angrier', 'angry', 'animal', 'animated', 'annoyed', 'annoying', 'another', 'answer', 'answering', 'any', 'anybody', 'anymore', 'anyone', 'anything', 'anytime', 'apartment', 'apologize', 'apology', 'app', 'appealing', 'apple', 'appreciate', 'april', 'aquarius', 'architect', 'are', 'aren', 'aries', 'arm', 'armageddon', 'armed', 'army', 'around', 'arrived', 'arsenal', 'art', 'artificial', 'artist', 'as', 'ashamed', 'ask', 'asked', 'asking', 'asleep', 'assembling', 'assessment', 'assist', 'assistant', 'assume', 'assuming', 'astronaut', 'astute', 'at', 'ate', 'atheist', 'athletic', 'attem', 'attempt', 'attempting', 'attractive', 'aunt', 'auntie', 'aunty', 'ava', 'available', 'avocado', 'await', 'aware', 'away', 'awesome', 'awful', 'awfully', 'baby', 'back', 'bacon', 'bad', 'badass', 'bagel', 'bake', 'baked', 'baking', 'balance', 'bald', 'ball', 'ballistic', 'ballroom', 'banana', 'band', 'bang', 'bar', 'barbecue', 'barcelona', 'barf', 'barrel', 'bartender', 'baseball', 'basic', 'basketball', 'bath', 'bay', 'bb', 'be', 'beach', 'bear', 'beastly', 'beat', 'beautiful', 'beauty', 'because', 'become', 'bed', 'bedbug', 'bee', 'beef', 'been', 'beer', 'before', 'beg', 'begging', 'begin', 'beige', 'beijing', 'being', 'believe', 'belly', 'bent', 'berlin', 'bernie', 'best', 'bestie', 'besties', 'bet', 'beto', 'better', 'between', 'beverage', 'beyond', 'bff', 'bffs', 'bicycle', 'biden', 'big', 'bigender', 'biggest', 'biggie', 'bike', 'biking', 'billy', 'bingo', 'bipolar', 'bird', 'birth', 'birthday', 'bisexual', 'bishop', 'bison', 'bit', 'bite', 'bixby', 'black', 'blah', 'blessed', 'blew', 'blogger', 'blond', 'blonde', 'blood', 'blossom', 'blow', 'blowing', 'blue', 'bluegrass', 'board', 'boat', 'body', 'bon', 'bonjour', 'book', 'boomer', 'bore', 'bored', 'boredom', 'boring', 'boringest', 'boringville', 'born', 'bos', 'boss', 'boston', 'bot', 'bought', 'bout', 'bow', 'bowel', 'bowl', 'bowling', 'boxer', 'boxing', 'boy', 'boyfriend', 'brainiac', 'branch', 'brand', 'brb', 'bread', 'breakfast', 'breathe', 'breeze', 'bridge', 'bright', 'brighter', 'brightest', 'brilliant', 'bring', 'brings', 'britain', 'bro', 'broken', 'brother', 'brownie', 'brunch', 'brunette', 'brush', 'bud', 'buddhist', 'buddy', 'buenas', 'buenos', 'bug', 'buh', 'build', 'built', 'bullseye', 'bummed', 'bummer', 'bummy', 'bump', 'bunch', 'bunk', 'bunny', 'burden', 'burger', 'burp', 'bursting', 'bus', 'business', 'busted', 'but', 'butt', 'butter', 'butterface', 'buy', 'buzzing', 'by', 'bye', 'c-3po', 'c-ya', 'ca', 'cairo', 'cake', 'calendar', 'call', 'called', 'calling', 'calm', 'calorie', 'camper', 'camping', 'can', 'canada', 'canadian', 'candle', 'candy', 'canning', 'canyon', 'capability', 'capable', 'capitalist', 'car', 'card', 'care', 'career', 'caring', 'carnivore', 'carpool', 'carry', 'cat', 'catch', 'catching', 'cause', 'celebrity', 'center', 'cereal', 'certainly', 'challenge', 'change', 'channel', 'character', 'charge', 'charmed', 'chat', 'chatbot', 'chatbots', 'chatter', 'chatting', 'check', 'checkbook', 'cheddar', 'cheer', 'cheerful', 'cheery', 'cheese', 'cheeseburger', 'chef', 'chew', 'chewing', 'chick', 'chicken', 'child', 'chillin', 'chinese', 'chip', 'chipper', 'chocolate', 'chopping', 'chore', 'christian', 'christmas', 'chuckle', 'chuffed', 'church', 'ciao', 'cigar', 'cisgender', 'citizenship', 'city', 'clam', 'clarify', 'class', 'classical', 'clean', 'clear', 'clearly', 'clever', 'cleverest', 'climb', 'climbing', 'close', 'clothing', 'cloud', 'clown', 'clowning', 'club', 'clubbing', 'code', 'coded', 'coder', 'coffee', 'cold', 'collar', 'collect', 'collecting', 'collection', 'college', 'color', 'coloring', 'colour', 'columbus', 'comb', 'comcast', 'come', 'comedian', 'comedy', 'comfortable', 'comic', 'coming', 'commit', 'committed', 'communist', 'company', 'competitive', 'complete', 'completely', 'compliment', 'comprehending', 'computer', 'con', 'concerned', 'concert', 'confused', 'confusing', 'conquer', 'conquering', 'conservative', 'constantly', 'constitution', 'consume', 'contest', 'conversation', 'cook', 'cookie', 'cookin', 'cooking', 'cooky', 'cool', 'coordinate', 'cop', 'cork', 'corporeal', 'correct', 'correctamundo', 'cortana', 'cougar', 'could', 'couldn', 'count', 'country', 'couple', 'cousin', 'cow', 'cpa', 'crack', 'crackin', 'cracking', 'crap', 'crappy', 'craving', 'crawl', 'crazy', 'cream', 'create', 'created', 'creating', 'creator', 'creature', 'cross', 'crossfit', 'crossword', 'cruel', 'crush', 'crushing', 'cry', 'cuddle', 'cuddling', 'cuisine', 'cup', 'curiosity', 'curious', 'current', 'currently', 'customer', 'cut', 'cute', 'cuter', 'cya', 'dad', 'daddy', 'dance', 'dancing', 'dang', 'danger', 'dangerous', 'dap', 'darn', 'dash', 'data', 'date', 'dating', 'day', 'de', 'dead', 'deal', 'dear', 'death', 'debate', 'decent', 'deed', 'deep', 'deer', 'define', 'definitely', 'definition', 'deformed', 'dejected', 'delhi', 'delicious', 'delight', 'delighted', 'delivered', 'demo', 'democracy', 'democrat', 'democratic', 'depart', 'deplore', 'depressed', 'depressing', 'depression', 'describe', 'deserted', 'design', 'designation', 'designed', 'designer', 'designing', 'desolate', 'despair', 'despairing', 'despise', 'despondent', 'dessert', 'destroy', 'destroying', 'destruction', 'detail', 'determined', 'detest', 'dev', 'develop', 'developed', 'developer', 'developing', 'dia', 'diagnostic', 'diagnostics', 'dice', 'did', 'die', 'diego', 'diet', 'different', 'digging', 'digital', 'dime', 'dine', 'ding', 'dining', 'dinner', 'director', 'directs', 'dirt', 'dirty', 'disgusting', 'dish', 'dislike', 'dismissed', 'disney', 'displeasing', 'disrupt', 'ditty', 'diver', 'divine', 'divorced', 'do', 'dock', 'doctor', 'doe', 'doesn', 'dog', 'doing', 'dollar', 'dolphin', 'dominate', 'domination', 'don', 'done', 'donut', 'doom', 'door', 'doubt', 'down', 'downcast', 'downhearted', 'downsizing', 'downtown', 'drag', 'draw', 'drawing', 'dream', 'dreaming', 'drink', 'drinking', 'drive', 'driven', 'driving', 'droid', 'dropped', 'drown', 'drug', 'dry', 'duck', 'dude', 'duel', 'duh', 'dull', 'dumb', 'dumber', 'dumbest', 'dummy', 'dump', 'dvd', 'dying', 'each', 'eagle', 'ear', 'early', 'earn', 'earth', 'easter', 'eat', 'eaten', 'eating', 'ecstatic', 'edm', 'educator', 'egg', 'eh', 'either', 'elaborate', 'elated', 'election', 'elephant', 'eliminated', 'eliminating', 'eliza', 'elope', 'else', 'email', 'embarrassingly', 'emotion', 'employed', 'employment', 'emu', 'enchante', 'encouraging', 'end', 'engaged', 'engineer', 'engineered', 'english', 'enjoy', 'enjoying', 'enough', 'enraged', 'enslave', 'enslaving', 'entertain', 'entertaining', 'enthusiastic', 'entitled', 'errand', 'especially', 'ethiopian', 'ethnicity', 'euphoric', 'eve', 'even', 'evenin', 'evening', 'ever', 'every', 'everybody', 'everyone', 'everything', 'evil', 'exact', 'exactly', 'exasperated', 'exasperating', 'excellent', 'exchange', 'excited', 'exciting', 'excuse', 'exercise', 'exist', 'expect', 'expected', 'expecting', 'experience', 'explain', 'express', 'extended', 'extrovert', 'eye', 'fab', 'fabulous', 'face', 'facebook', 'facsimile', 'fact', 'fail', 'failed', 'failing', 'fair', 'fake', 'fall', 'fallen', 'falling', 'false', 'familiar', 'family', 'famished', 'fan', 'fantastic', 'fantasy', 'far', 'fare', 'farewell', 'fart', 'farted', 'fascinating', 'fast', 'fat', 'father', 'fav', 'fave', 'favor', 'favorite', 'favourite', 'fear', 'feed', 'feel', 'feeling', 'feliz', 'fell', 'female', 'festivus', 'fever', 'few', 'fiction', 'fight', 'fighter', 'figure', 'fill', 'film', 'finally', 'find', 'finding', 'fine', 'finger', 'fingernail', 'fire', 'fired', 'firing', 'first', 'fish', 'fishing', 'fist', 'five', 'flapping', 'flash', 'flavor', 'fleek', 'flesh', 'flexible', 'flick', 'flip', 'flipped', 'flirting', 'floating', 'flower', 'flu', 'fluffy', 'fly', 'flying', 'fold', 'folk', 'follow', 'following', 'fond', 'food', 'fool', 'foolin', 'fooling', 'football', 'for', 'force', 'forest', 'forever', 'forget', 'forgive', 'forgiveness', 'forgot', 'form', 'forming', 'forward', 'fourth', 'fox', 'frankfurt', 'freaking', 'free', 'french', 'frequency', 'fresh', 'fret', 'friday', 'friend', 'friendless', 'friendly', 'friendship', 'frightened', 'from', 'fruit', 'fry', 'fuggitaboutit', 'fugmo', 'full', 'fun', 'function', 'functional', 'functioning', 'funnier', 'funniest', 'funny', 'furious', 'future', \"g'day\", \"g'devenin\", \"g'devening\", \"g'night\", 'g2g', 'gal', 'game', 'gangsta', 'gangster', 'garden', 'gardening', 'gasket', 'gay', 'geez', 'gem', 'gen', 'gender', 'gendered', 'genderfluid', 'genderqueer', 'genius', 'german', 'gerty', 'get', 'getting', 'ghost', 'giant', 'giddy', 'gig', 'giggle', 'gim', 'girl', 'girlfriend', 'give', 'giving', 'glad', 'glass', 'glaze', 'glazed', 'global', 'gloomy', 'glorious', 'glum', 'go', 'goal', 'god', 'going', 'golden', 'golf', 'golfer', 'golfing', 'gon', 'gone', 'gong', 'good', 'goodbye', 'goof', 'goofed', 'goofing', 'google', 'gorgeous', 'gosh', 'gossip', 'got', 'gotcha', 'gracias', 'graduated', 'grand', 'grandfather', 'grandma', 'grandmother', 'grandpa', 'grandparent', 'grateful', 'great', 'greater', 'greatest', 'green', 'greeting', 'grocery', 'groovy', 'gross', 'grotesque', 'groundhog', 'grow', 'growling', 'grown', 'grownup', 'grudge', 'guess', 'guessing', 'guitar', 'gum', 'gun', 'gut', 'guten', 'guy', 'gym', 'ha', 'had', 'hah', 'haha', 'hahaha', 'hahahaha', 'hail', 'hailing', 'hair', 'haircut', 'hal', 'halloween', 'hand', 'handle', 'handsome', 'hang', 'hangin', 'hanging', 'hangry', 'hannukah', 'hanukkah', 'hap', 'happened', 'happening', 'happier', 'happiest', 'happiness', 'happs', 'happy', 'har', 'harbinger', 'hard', 'harder', 'harm', 'harris', 'hate', 'have', 'having', 'hawaii', 'he', 'head', 'headed', 'heading', 'heal', 'health', 'hear', 'heard', 'hearing', 'heart', 'heartbeat', 'heartbreaking', 'heartbroken', 'hearted', 'heated', 'heck', 'hee', 'heel', 'heh', 'hell', 'hell-bent', 'hello', 'help', 'her', 'here', 'hero', 'hey', 'hey-hey', 'heya', 'hi', 'hi-ya', 'hideous', 'high', 'hike', 'hiking', 'hilarious', 'him', 'hindu', 'hip', 'hispanic', 'history', 'hit', 'hitched', 'hiya', 'ho', 'hobby', 'hockey', 'hold', 'hole', 'holiday', 'holy', 'home', 'homely', 'hometown', 'homework', 'homie', 'honest', 'honestly', 'hong', 'honor', 'hood', 'hook', 'hooray', 'hoosier', 'hop', 'hope', 'hopeless', 'hoping', 'horrible', 'horror', 'horse', 'hot', 'hotter', 'house', 'how', 'howdy', 'hubby', 'hug', 'huh', 'hum', 'human', 'humanity', 'humble', 'humblest', 'humor', 'humorous', 'hundred', 'hunger', 'hungover', 'hungry', 'hunting', 'hurt', 'husband', 'hush', 'hyderbad', 'i', 'ice', 'idea', 'ideal', 'identical', 'identify', 'identity', 'idiot', 'idiotic', 'if', 'imaginary', 'imagine', 'immigrant', 'important', 'impossible', 'impressed', 'impressive', 'in', 'inaccurate', 'incensed', 'incompetent', 'inconsolable', 'incorporated', 'incredible', 'independence', 'independent', 'india', 'indian', 'indigenous', 'indubitably', 'inform', 'information', 'infuriated', 'infuriating', 'insect', 'inspired', 'instagram', 'instrument', 'intelligence', 'intelligent', 'intend', 'intent', 'interest', 'interested', 'interesting', 'internet', 'intestine', 'intimidating', 'into', 'introduce', 'introduction', 'introvert', 'invite', 'involved', 'irate', 'irish', 'irrelevant', 'irritated', 'irritating', 'is', 'isolated', 'it', 'italian', 'janky', 'japanese', 'jaw', 'jazz', 'jeez', 'jet', 'jetting', 'jewish', 'jk', 'job', 'jobless', 'joke', 'joker', 'joking', 'jolly', 'joshing', 'journaling', 'journalist', 'joy', 'joyeux', 'joyful', 'joyous', 'jr.', 'july', 'jump', 'jury', 'just', 'k', 'keep', 'keeper', 'keeping', 'keto', 'key', 'kid', 'kidding', 'kill', 'killed', 'killing', 'kind', 'kindly', 'king', 'kite', 'knee', 'knew', 'knock', 'knot', 'know', 'knowledgeable', 'koala', 'kong', 'kooky', 'korean', 'kthx', 'kwanza', 'kwanzaa', 'l8r', 'la', 'lab', 'lady', 'lamb', 'lame', 'lamest', 'lamp', 'laptop', 'last', 'late', 'lately', 'later', 'latest', 'latina', 'latino', 'laugh', 'laughing', 'laundry', 'law', 'lawn', 'lawyer', 'lazy', 'le', 'leader', 'learn', 'learning', 'least', 'leave', 'leaving', 'left', 'leftover', 'leg', 'legit', 'lemonade', 'leo', 'let', 'letting', 'level', 'liberal', 'libertarian', 'libra', 'librarian', 'library', 'lid', 'life', 'lifeform', 'lift', 'light', 'likable', 'like', 'likeable', 'liked', 'likely', 'limited', 'line', 'lion', 'lip', 'listen', 'listening', 'litterbox', 'little', 'live', 'livelihood', 'liver', 'livid', 'living', 'lmao', 'loathe', 'lobster', 'local', 'located', 'location', 'log', 'logging', 'lol', 'lololol', 'london', 'lonely', 'lonesome', 'long', 'longer', 'look', 'looking', 'loool', 'looooool', 'lord', 'los', 'lose', 'losing', 'lost', 'lot', 'loud', 'love', 'lovely', 'loving', 'low', 'lowdown', 'luck', 'lunch', 'lung', 'luther', 'm', 'machine', 'mad', 'maddening', 'madder', 'made', 'madrid', 'main', 'make', 'maker', 'making', 'male', 'malevolent', 'malicious', 'mall', 'mama', 'man', 'manager', 'manifest', 'manifested', 'many', 'map', 'market', 'marriage', 'married', 'marry', 'martin', 'marvelous', 'mask', 'massage', 'master', 'masticate', 'match', 'mate', 'mater', 'material', 'matrix', 'matter', 'maui', 'may', 'mayor', 'mazel', 'me', 'meal', 'mean', 'meaning', 'meant', 'medication', 'meditate', 'meditation', 'meet', 'meeting', 'melancholy', 'member', 'meme', 'memorial', 'mention', 'merry', 'message', 'messed', 'messing', 'met', 'mexican', 'mexico', 'mic', 'middle', 'middle-aged', 'midnight', 'might', 'milan', 'milkshake', 'millennial', 'million', 'mind', 'minute', 'miserable', 'miss', 'missed', 'missing', 'mission', 'mistake', 'moi', 'mom', 'moment', 'momma', 'mommy', 'monday', 'money', 'monkies', 'monogamous', 'month', 'mood', 'moon', 'more', 'morgen', 'mornin', 'morning', 'moron', 'morrow', 'most', 'mother', 'motor', 'motoring', 'mountain', 'moustache', 'mouth', 'move', 'movie', 'mow', 'mozzarella', 'much', 'munchies', 'museum', 'music', 'muslim', 'must', 'my', 'myself', 'mystery', \"n'kay\", \"n't\", 'na', 'nada', 'nail', 'nailed', 'name', 'nastay', 'nasty', 'national', 'native', 'navidad', 'near', 'nearby', 'neat', 'neato', 'need', 'needed', 'nervous', 'netflix', 'neutral', 'never', 'new', 'news', 'newspaper', 'next', 'nice', 'nicely', 'nickname', 'night', 'nighters', 'nighty', 'niiice', 'nine', 'no', 'nobody', 'noches', 'noel', 'noise', 'nola', 'nom', 'noms', 'non', 'nonbinary', 'none', 'nope', 'normal', 'not', 'notch', 'nothing', 'notice', 'novel', 'now', 'nowhere', 'nurse', 'nyc', 'o', 'object', 'obliterate', 'obsessed', 'obviously', 'occupation', 'odd', 'of', 'off', 'offended', 'offense', 'office', 'official', 'offing', 'often', 'oh', 'ok', 'okay', 'old', 'older', 'omg', 'on', 'one', 'online', 'only', 'oops', 'oopsie', 'open', 'opinion', 'opposite', 'or', 'organic', 'organized', 'origami', 'oscar', 'other', 'our', 'out', 'outrage', 'outraged', 'outside', 'outstanding', 'outta', 'over', 'overdose', 'overjoyed', 'overtake', 'overthrow', 'overweight', 'own', 'owns', 'package', 'packing', 'pagan', 'page', 'pain', 'paint', 'painting', 'pal', 'pancake', 'pant', 'papa', 'paper', 'paradise', 'pardon', 'parent', 'paris', 'park', 'part', 'part-time', 'partner', 'party', 'past', 'pasta', 'pat', 'pathetic', 'patrick', 'peace', 'peachy', 'peanut', 'peckish', 'pee', 'peep', 'peeved', 'penguin', 'people', 'percent', 'perfect', 'perfecto', 'performing', 'person', 'personality', 'personally', 'pet', 'phone', 'photo', 'physical', 'piano', 'pick', 'picking', 'picture', 'pie', 'piece', 'pierced', 'pill', 'pineapple', 'pink', 'pirate', 'pisces', 'pissed', 'pitter', 'pixar', 'pizza', 'place', 'plan', 'plane', 'planning', 'plant', 'platform', 'play', 'playing', 'playoff', 'pleasant', 'please', 'pleased', 'pleasure', 'plot', 'plotting', 'podcasts', 'poetry', 'point', 'poker', 'politics', 'polyamorous', 'pond', 'pony', 'pool', 'poop', 'pop', 'popcorn', 'poppa', 'poppin', 'popping', 'pork', 'portend', 'position', 'positively', 'possible', 'post', 'pot', 'power', 'prank', 'pranking', 'prankster', 'pray', 'prayer', 'predict', 'prefer', 'pregnant', 'preparing', 'present', 'president', 'pretend', 'prettier', 'prettiest', 'pretty', 'probably', 'problem', 'produced', 'product', 'profession', 'professional', 'program', 'programmed', 'programmer', 'programming', 'project', 'prom', 'properly', 'propose', 'prost', 'pulling', 'pumped', 'pumpkin', 'punch', 'puppy', 'purpose', 'put', 'puzzle', 'queen', 'queer', 'question', 'queue', 'quiet', 'quit', 'quite', 'quote', 'r', 'r2-d2', 'rabbit', 'race', 'rad', 'radical', 'radio', 'rage', 'raging', 'rain', 'raining', 'rainy', 'random', 'rap', 'razor', 're', 'read', 'reading', 'ready', 'real', 'realize', 'really', 'recite', 'record', 'red', 'redhead', 'refer', 'refresh', 'registering', 'regular', 'related', 'relationship', 'relative', 'relevant', 'relief', 'religious', 'remember', 'remorseful', 'remote', 'repeat', 'repeating', 'repetitive', 'rephrase', 'report', 'republican', 'repulsive', 'request', 'require', 'required', 'reside', 'respond', 'response', 'responsible', 'restate', 'restaurant', 'retire', 'retriever', 'return', 'returned', 'revolting', 'ride', 'ridiculous', 'riding', 'right', 'righto', 'ring', 'rinse', 'rise', 'road', 'robby', 'robot', 'rock', 'rockstar', 'rofl', 'roger', 'rogue', 'role', 'roll', 'romance', 'romantic', 'romantically', 'room', 'roommate', 'rope', 'routine', 'rule', 'rumbling', 'run', 'runner', 'running', 'russian', 'ryokai', 's', 'sad', 'saddest', 'sadness', 'said', 'sailing', 'salesman', 'salutation', 'salute', 'samantha', 'same', 'san', 'sandwich', 'sang', 'saturday', 'sauce', 'say', 'saying', 'sayonara', 'scared', 'scary', 'scheme', 'scheming', 'school', 'science', 'scientist', 'scoop', 'scoot', 'scooting', 'scratch', 'screwing', 'sculpting', 'sculpture', 'scuse', 'seahawks', 'season', 'seattle', 'sec', 'second', 'see', 'seeing', 'seem', 'seems', 'seen', 'self', 'self-employed', 'send', 'senior', 'sense', 'sentient', 'sequitur', 'serenade', 'serious', 'seriously', 'serve', 'server', 'service', 'set', 'settle', 'sewing', 'sex', 'sexy', 'shake', 'shaking', 'shall', 'shalom', 'shame', 'shanghai', 'share', 'sharp', 'shhh', 'shift', 'shine', 'shitless', 'shoe', 'shoot', 'shop', 'shopping', 'short', 'shortly', 'shot', 'should', 'show', 'shredded', 'shush', 'shut', 'shutting', 'shy', 'si', 'sib', 'sibling', 'sick', 'side', 'sight', 'sign', 'significant', 'signing', 'silence', 'silent', 'silliness', 'silly', 'simply', 'sin', 'since', 'sincere', 'sincerely', 'sing', 'singer', 'singing', 'single', 'singularity', 'sinister', 'sir', 'siri', 'sister', 'sitting', 'situation', 'size', 'sk8r', 'skedaddle', 'skedaddling', 'skiing', 'skill', 'skin', 'skinny', 'skip', 'skydiving', 'skynet', 'slap', 'slapper', 'sleep', 'sleeping', 'sleeve', 'slide', 'slip', 'slit', 'slow', 'small', 'smart', 'smarter', 'smartest', 'smarty', 'smartypants', 'smell', 'smile', 'smiling', 'smitten', 'smoke', 'smoking', 'smooth', 'snack', 'sneeze', 'snooze', 'snow', 'so', 'soccer', 'socialist', 'society', 'sock', 'soda', 'sofa', 'softball', 'soir', 'solitaire', 'solitary', 'solstice', 'some', 'somebody', 'someday', 'someone', 'somersault', 'something', 'sometime', 'sometimes', 'somewhere', 'song', 'soon', 'sorry', 'sort', 'soul', 'soulmate', 'sound', 'speak', 'speaking', 'special', 'spectacular', 'spectrum', 'speech', 'spell', 'spend', 'spirit', 'spirited', 'sport', 'spouse', 'spring', 'squeeze', 'squirrel', 'srry', 'srsly', 'sry', 'st.', 'stale', 'stand', 'star', 'starshine', 'start', 'started', 'starting', 'starving', 'state', 'statement', 'stay', 'steady', 'steak', 'steaming', 'stellar', 'stick', 'stiff', 'still', 'stink', 'stomach', 'stop', 'stopped', 'store', 'story', 'straight', 'strange', 'strawberry', 'stroke', 'strong', 'stuck', 'student', 'study', 'stuff', 'stuffed', 'stunning', 'stupendous', 'stupid', 'stupidest', 'subject', 'submit', 'such', 'suck', 'sucked', 'suicidal', 'suicide', 'suit', 'summer', 'sun', 'sunday', 'sung', 'sunny', 'sunshine', 'sup', 'super', 'superbowl', 'superior', 'superpower', 'supervises', 'supervisor', 'suppertime', 'supporter', 'suppose', 'supposed', 'sure', 'surfing', 'surprise', 'surprised', 'survive', 'sushi', 'suspect', 'sustenance', 'sweat', 'sweet', 'sweetheart', 'sweetie', 'swell', 'swim', 'swimmer', 'swimming', 'swing', 'switch', 'sync', 'system', 't', 'ta', 'tack', 'taco', 'tad', 'tada', 'tail', 'take', 'taking', 'talk', 'talked', 'talkin', 'talking', 'tall', 'tan', 'tardes', 'target', 'task', 'tattoo', 'taurus', 'tay', 'tea', 'teach', 'teacher', 'team', 'tech', 'technology', 'ted', 'tee', 'teehee', 'teen', 'teenager', 'teeth', 'teleport', 'television', 'tell', 'temper', 'temperature', 'tennis', 'teriyaki', 'term', 'terminate', 'terminated', 'terminating', 'terrible', 'terribly', 'terrified', 'test', 'testing', 'text', 'thai', 'than', 'thank', 'thankful', 'thanks', 'thanksgiving', 'that', 'thats', 'the', 'theater', 'thee', 'their', 'them', 'then', 'therapy', 'there', 'these', 'they', 'thick', 'thing', 'think', 'thinking', 'third', 'this', 'thnx', 'those', 'thou', 'though', 'thought', 'threat', 'three', 'thrilled', 'throw', 'throwing', 'thursday', 'thus', 'thx', 'ticked', 'tickled', 'tidings', 'tidy', 'tie', 'tied', 'tiger', 'till', 'time', 'tired', 'title', 'to', 'toast', 'today', 'toe', 'tofu', 'tokyo', 'told', 'tomato', 'tomorrow', 'ton', 'tonight', 'too', 'toodle-oo', 'top', 'topping', 'totally', 'tov', 'toward', 'town', 'traffic', 'train', 'trans', 'transgender', 'trap', 'trash', 'travel', 'traveling', 'travelling', 'treating', 'tree', 'trick', 'trip', 'trivia', 'true', 'truly', 'trump', 'trumpet', 'truth', 'truuuuu', 'truuuuue', 'try', 'trying', 'tubular', 'tuesday', 'tummy', 'tune', 'turn', 'turning', 'tv', 'tweet', 'twirling', 'two', 'type', 'typed', 'u', 'uggerz', 'uggo', 'ugh', 'ugliest', 'ugly', 'uh', 'uhhuh', 'ultimate', 'umbrella', 'umm', 'unattractive', 'uncle', 'under', 'understand', 'understanding', 'understood', 'underweight', 'undoubtedly', 'unemployed', 'uneventful', 'unfunny', 'unhappy', 'unhelpful', 'uninteresting', 'universe', 'unquestionably', 'untrue', 'up', 'upbeat', 'update', 'uprising', 'upset', 'ur', 'use', 'useless', 'using', 'usual', 'usually', 'utterly', 'uuuuuggggllyy', 'vacation', 'valentine', 'vanpool', 'variety', 've', 'vega', 'vegan', 'vegetable', 'vegetarian', 'very', 'veteran', 'vexed', 'vexing', 'video', 'vietnamese', 'virgo', 'visit', 'voice', 'volleyball', 'vomit', 'vote', 'voted', 'vow', 'wa', 'wack', 'wacky', 'wait', 'waiting', 'wake', 'walk', 'walking', 'wall', 'wall-e', 'wan', 'want', 'wanted', 'warm', 'warren', 'wash', 'watch', 'watching', 'water', 'way', 'wazzup', 'we', 'weak', 'wear', 'weather', 'wedding', 'wednesday', 'weed', 'week', 'weekend', 'weight', 'weird', 'welcome', 'welk', 'well', 'went', 'were', 'whack', 'whale', 'what', 'whatdya', 'whatever', 'when', 'where', 'whether', 'which', 'white', 'who', 'whoa', 'whole', 'whom', 'whoop', 'whose', 'why', 'wife', 'wild', 'will', 'willis', 'win', 'window', 'wine', 'winter', 'wipe', 'wise', 'wisecrack', 'wisecracking', 'wish', 'wishing', 'with', 'without', 'witty', 'wo', 'woeful', 'woman', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woodworking', 'word', 'work', 'worker', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'worthless', 'wot', 'would', 'wow', 'wrist', 'write', 'writer', 'writes', 'written', 'wrong', 'wrote', 'wtf', 'y', 'ya', 'yap', 'yawn', 'yay', 'yeah', 'year', 'yellow', 'yep', 'yes', 'yikes', 'yo', 'yoga', 'yoohoo', 'york', 'you', 'young', 'younger', 'your', 'yours', 'yourself', 'yucky', 'yuletide', 'yup', 'z', 'zealand', 'zip', 'zit', 'zo', 'zoo', 'zzz', '’']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "words = sorted(list(set([lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words])))\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between questions and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique lemmatized words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    question_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    question_words = [lemmatizer.lemmatize(word.lower()) for word in question_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in question_words else bag.append(0)\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1210999  | total loss: \u001b[1m\u001b[32m0.05785\u001b[0m\u001b[0m | time: 4.259s\n",
      "| Adam | epoch: 1000 | loss: 0.05785 - acc: 0.9963 -- iter: 9680/9682\n",
      "Training Step: 1211000  | total loss: \u001b[1m\u001b[32m0.05207\u001b[0m\u001b[0m | time: 4.262s\n",
      "| Adam | epoch: 1000 | loss: 0.05207 - acc: 0.9967 -- iter: 9682/9682\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\P\\Desktop\\Projects\\python-project-chatbot-codes\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "tensorflow.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(np.array(train_x)[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(np.array(train_y)[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(np.array(train_x), np.array(train_y), n_epoch=1000, batch_size=8, show_metric=True)\n",
    "model.save(\"model.tflearn\")\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words) \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    resi = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(resi) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = str(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return (res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating GUI with tkinter\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"Kaori: \" + str(res).strip('[' ']') + '\\n\\n')\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    "base = Tk()\n",
    "base.title(\"Kaori- A Talkative retrievel ChatBot ;>\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "#Create Chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"#d2afff\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
    "ChatLog.config(state=DISABLED)\n",
    "#Bind scrollbar to Chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "#Create Button to send message\n",
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"10\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                    command= send )\n",
    "#Create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"#82a9c1\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "#EntryBox.bind(\"<Return>\", send)\n",
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=330, width=370)\n",
    "EntryBox.place(x=6, y=350, height=90, width=370)\n",
    "SendButton.place(x=6, y=450, height=40, width=370)\n",
    "base.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
